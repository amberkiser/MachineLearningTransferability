{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_pickle('../data/baseline_data.pkl')\n",
    "grouped_data = pd.read_pickle('../data/grouped_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_baseline = baseline_data.drop(columns=['SSI','PNEUMO','UTI','SEPSIS'])\n",
    "y_baseline_SSI = baseline_data['SSI']\n",
    "\n",
    "X_grouped = grouped_data.drop(columns=['SSI','PNEUMO','UTI','SEPSIS'])\n",
    "y_grouped_SSI = grouped_data['SSI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 0.3\n",
    "\n",
    "X_base_trn, X_base_tst, y_base_trn, y_base_tst = train_test_split(X_baseline, y_baseline_SSI, test_size=split_size, \n",
    "                                                                  stratify=y_baseline_SSI, random_state=1)\n",
    "\n",
    "X_base_trn = X_base_trn.reset_index(drop=True)\n",
    "X_base_tst = X_base_tst.reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_group_trn, X_group_tst, y_group_trn, y_group_tst = train_test_split(X_grouped, y_grouped_SSI, \n",
    "                                                                      test_size=split_size, stratify=y_grouped_SSI,\n",
    "                                                                      random_state=2)\n",
    "\n",
    "X_group_trn = X_group_trn.reset_index(drop=True)\n",
    "X_group_tst = X_group_tst.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "Identify outliers and set to highest/lowest value.\n",
    "\n",
    "Find values less or greater than 6 std from mean. Change these to the min/max value (that is not 6 std from mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_std_data(lab_data):\n",
    "    mean = lab_data.mean()\n",
    "    mean.name = 'mean'\n",
    "\n",
    "    std = lab_data.std()\n",
    "    std.name = 'std'\n",
    "\n",
    "    gran_agg = pd.concat([mean, std], axis=1)\n",
    "    gran_agg['std+6'] = gran_agg['mean'] + gran_agg['std'] * 6\n",
    "    gran_agg['std-6'] = gran_agg['mean'] - gran_agg['std'] * 6\n",
    "    return(gran_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_base_cols = [col for col in X_base_trn.columns if re.search(r'LAB', col)]\n",
    "lab_base_trn = X_base_trn[lab_base_cols]\n",
    "lab_base_tst = X_base_tst[lab_base_cols]\n",
    "\n",
    "lab_group_cols = [col for col in X_group_trn.columns if re.search(r'LAB', col)]\n",
    "lab_group_trn = X_group_trn[lab_group_cols]\n",
    "lab_group_tst = X_group_tst[lab_group_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline outliers\n",
    "agg_data = create_std_data(lab_base_trn)\n",
    "\n",
    "for i in range(len(agg_data.index)):\n",
    "    column_name = agg_data.index[i]\n",
    "    \n",
    "    # Max outliers\n",
    "    std6 = agg_data.loc[agg_data.index == column_name, 'std+6'].values[0]\n",
    "    \n",
    "    out_trn_index = lab_base_trn.loc[lab_base_trn[column_name] > std6].index.tolist()\n",
    "    max_value = lab_base_trn[column_name].drop(axis=0, index=out_trn_index).max()\n",
    "    \n",
    "    out_tst_index = lab_base_tst.loc[lab_base_tst[column_name] > std6].index.tolist()\n",
    "\n",
    "    for ind in out_trn_index:\n",
    "        X_base_trn.at[ind, column_name] = max_value\n",
    "    for ind in out_tst_index:\n",
    "        X_base_tst.at[ind, column_name] = max_value\n",
    "        \n",
    "    # Min outliers\n",
    "    std6 = agg_data.loc[agg_data.index == column_name, 'std-6'].values[0]\n",
    "    \n",
    "    out_trn_index = lab_base_trn.loc[lab_base_trn[column_name] < std6].index.tolist()\n",
    "    min_value = lab_base_trn[column_name].drop(axis=0, index=out_trn_index).min()\n",
    "    \n",
    "    out_tst_index = lab_base_tst.loc[lab_base_tst[column_name] < std6].index.tolist()\n",
    "\n",
    "    for ind in out_trn_index:\n",
    "        X_base_trn.at[ind, column_name] = min_value\n",
    "    for ind in out_tst_index:\n",
    "        X_base_tst.at[ind, column_name] = min_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped outliers\n",
    "agg_data = create_std_data(lab_group_trn)\n",
    "\n",
    "for i in range(len(agg_data.index)):\n",
    "    column_name = agg_data.index[i]\n",
    "    \n",
    "    # Max outliers\n",
    "    std6 = agg_data.loc[agg_data.index == column_name, 'std+6'].values[0]\n",
    "    \n",
    "    out_trn_index = lab_group_trn.loc[lab_group_trn[column_name] > std6].index.tolist()\n",
    "    max_value = lab_group_trn[column_name].drop(axis=0, index=out_trn_index).max()\n",
    "    \n",
    "    out_tst_index = lab_group_tst.loc[lab_group_tst[column_name] > std6].index.tolist()\n",
    "\n",
    "    for ind in out_trn_index:\n",
    "        X_group_trn.at[ind, column_name] = max_value\n",
    "    for ind in out_tst_index:\n",
    "        X_group_tst.at[ind, column_name] = max_value\n",
    "        \n",
    "    # Min outliers\n",
    "    std6 = agg_data.loc[agg_data.index == column_name, 'std-6'].values[0]\n",
    "    \n",
    "    out_trn_index = lab_group_trn.loc[lab_group_trn[column_name] < std6].index.tolist()\n",
    "    min_value = lab_group_trn[column_name].drop(axis=0, index=out_trn_index).min()\n",
    "    \n",
    "    out_tst_index = lab_group_tst.loc[lab_group_tst[column_name] < std6].index.tolist()\n",
    "\n",
    "    for ind in out_trn_index:\n",
    "        X_group_trn.at[ind, column_name] = min_value\n",
    "    for ind in out_tst_index:\n",
    "        X_group_tst.at[ind, column_name] = min_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "Find medians of labs in training set and impute missing labs from training and validation sets with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lab_medians(X_train):\n",
    "    lab_cols = [col for col in X_train.columns if re.search(r'LAB_', col)]\n",
    "    lab_medians = dict(X_train[lab_cols].median(axis=0))\n",
    "    return(lab_medians)\n",
    "\n",
    "def save_lab_medians(lab_medians, fname):\n",
    "    with open('../data/medians/%s_lab_medians.pkl' %fname,'wb') as f:\n",
    "        pickle.dump(lab_medians, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSI_base_medians = get_lab_medians(X_base_trn)\n",
    "save_lab_medians(SSI_base_medians, 'SSI_baseline')\n",
    "X_base_trn = X_base_trn.fillna(SSI_base_medians)\n",
    "X_base_tst = X_base_tst.fillna(SSI_base_medians)\n",
    "\n",
    "SSI_group_medians = get_lab_medians(X_group_trn)\n",
    "save_lab_medians(SSI_group_medians, 'SSI_grouped')\n",
    "X_group_trn = X_group_trn.fillna(SSI_group_medians)\n",
    "X_group_tst = X_group_tst.fillna(SSI_group_medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframes\n",
    "Save dataframes as pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base_trn.to_pickle('../data/split_sets/X_baseline_train_SSI.pkl')\n",
    "X_base_tst.to_pickle('../data/split_sets/X_baseline_test_SSI.pkl')\n",
    "y_base_trn.to_pickle('../data/split_sets/y_baseline_train_SSI.pkl')\n",
    "y_base_tst.to_pickle('../data/split_sets/y_baseline_test_SSI.pkl')\n",
    "\n",
    "X_group_trn.to_pickle('../data/split_sets/X_grouped_train_SSI.pkl')\n",
    "X_group_tst.to_pickle('../data/split_sets/X_grouped_test_SSI.pkl')\n",
    "y_group_trn.to_pickle('../data/split_sets/y_grouped_train_SSI.pkl')\n",
    "y_group_tst.to_pickle('../data/split_sets/y_grouped_test_SSI.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
