{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "## Feature Selection\n",
    "Perform feature selection using ANOVA f-score on training data. For granular - choose 5, 10, 25, 50, 100, 500, 1000, 5000 features. For grouped - choose 5, 10, 25, 50, 100, 500 features.<br/>\n",
    "See script.\n",
    "\n",
    "## Hyperparameters\n",
    "Using 10-fold CV, tune model hyperparameters to have best AUC and F1 for each outcome. Implement random undersampling to deal with class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining tuning results for each outcome and dataset\n",
    "\n",
    "dataset = ['baseline', 'grouped']\n",
    "algorithms = ['lr','rf','svm','xgb']\n",
    "feature_num = {'baseline': [5,10,25,50,100,500,1000,5000,9559], \n",
    "               'grouped': [5,10,25,50,100,500,805]}\n",
    "\n",
    "for ds in dataset:\n",
    "    results_combined = pd.DataFrame()\n",
    "    column_names = ['number_of_features','algorithm','Parameter_combo','Acc_val','Acc_rank','F1_val',\n",
    "                    'F1_rank','AUC_val','AUC_rank','Acc_train','F1_train','AUC_train']\n",
    "\n",
    "    for num in feature_num[ds]:\n",
    "        for a in algorithms:\n",
    "            temp = pd.read_csv('../../results/tuning/individual_results/%s/SSI_%s_%d.csv' %(ds, a, num))\n",
    "            temp = temp.drop(columns='Unnamed: 0')\n",
    "            temp['number_of_features'] = num\n",
    "            temp['algorithm'] = a\n",
    "            results_combined = pd.concat([results_combined, temp])\n",
    "\n",
    "    results_combined = results_combined[column_names].reset_index(drop=True)\n",
    "    results_combined['Acc_rank'] = results_combined['Acc_val'].rank(method='min', ascending=False)\n",
    "    results_combined['F1_rank'] = results_combined['F1_val'].rank(method='min', ascending=False)\n",
    "    results_combined['AUC_rank'] = results_combined['AUC_val'].rank(method='min', ascending=False)\n",
    "            \n",
    "    filename='../../results/tuning/SSI_%s_tuning_results.csv' % ds\n",
    "    results_combined.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually choose optimal parameters for each outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
